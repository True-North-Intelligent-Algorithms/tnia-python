{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Napari-Easy-Augment-Batch-DL to load and label images\n",
    "\n",
    "This notebook starts up Napari-Easy-Augment-Batch-DL and points it to our project directory.  At the beginning of a project this directory is simply the location of our collection of images.  For the light sheet vessel example it will be the 2D slices we extracted and saved in the ```10_generate_training_slices``` notebook. \n",
    "\n",
    "For an overview of how ```napari-easy-augment-batch-dl``` is used to load and label images, and how data should be organized see [here](https://true-north-intelligent-algorithms.github.io/napari-easy-augment-batch-dl/load_and_label/).\n",
    "\n",
    "## Sparse labeling\n",
    "\n",
    "In this example we will use sparse labeling.  \n",
    "\n",
    "**Sparse Labeling**:  Not every pixel has to be labeled.  However some background needs to be labeled to differentiate between background pixels and unlabeled pixels.  For example if there were 2 foreground classes use label 1 for background, 2 for \"class 1\", and 3 for \"class 2\".  Unlabeled pixels (0) will be ignored. \n",
    "\n",
    "**Dense Labeling**:  Every foreground pixel needs to be labeled however background does not need to be labeled.  If there were 2 foreground classes, use 1 for \"class 1\", 2 for \"class 2\" and then the remaining pixels (0) will be treated as background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster_geometry not imported.  This is only needed for the ellipsoid rendering in apply_stardist\n",
      "No module named 'segment_everything'\n",
      "napari version 0.5.6\n",
      "numpy version 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl\n",
    "\n",
    "# for trouble shooting print the napari and numpy version. This can give us clues if there are dependency issues\n",
    "print('napari version', napari.__version__)\n",
    "print('numpy version', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CellPoseInstanceFramework not loaded\n",
      "No module named 'segment_everything'\n",
      "Found framework PytorchSemanticFramework\n",
      "Zarr store already up-to-date.\n",
      "Zarr store already up-to-date.\n",
      "Error creating ml_labels: 'Random Forest Model'\n",
      "Random Forest ML may not work properly\n",
      "Adding object boxes layer\n",
      "Adding predicted object boxes layer\n",
      "Adding label boxes\n",
      "Adding object boxes\n",
      "Adding predicted object boxes\n",
      "Setting object box classes\n",
      "Setting predicted object box classes\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "parent_path = r'D:\\images\\tnia-python-images\\imagesc\\2025_03_19_vessel_3D_lightsheet'\n",
    "batch_dl.load_image_directory(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy_augment_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
