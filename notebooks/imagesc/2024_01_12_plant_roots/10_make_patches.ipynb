{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make patches from labels \n",
    "\n",
    "This notebook shows how to make patches from labels\n",
    "\n",
    "For the purpose of this notebook we use the following definitions\n",
    "\n",
    "1.  Label - set of annotations for an image.\n",
    "2.  Patch - a crop of the 'label' that is ready to be an input to train a neural network.\n",
    "\n",
    "Patches are essentially crops from the label. The size of the patch is the input size of the network.  \n",
    "\n",
    "There are different strategies to make patches.  In this notebook we create a ordered set of patches to cover the entire image.\n",
    "\n",
    "For example if the image is 512 by 512 and the patch size is 256 by 256 we create 4 patches.  If the image is say 400 by 400 we still create 4 256 by 256 patches but they will have an overlap. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the image and previous segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imsave\n",
    "import napari\n",
    "from tnia.deeplearning.dl_helper import make_patch_directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "tnia_images_path = Path(r'D:/images')\n",
    "parent_path=Path(tnia_images_path / r'tnia-python-images/imagesc/2024_01_12_plant_roots')\n",
    "name = '21_force_filtered'\n",
    "im = imread(os.path.join(parent_path / (name+\".tif\")))\n",
    "\n",
    "#labels = np.zeros(im.shape, dtype=np.uint8)\n",
    "labels = imread(os.path.join(parent_path / (name+\"_labeled_.tif\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folders for input and ground truth patches\n",
    "\n",
    "When we train a neural network we usually use small patches.  So create a directory for input (the original image) and ground truth (the labels) patches, then save the patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= parent_path / 'labels'\n",
    "image_patch_path =  train_path / 'input0'\n",
    "label_patch_path =  train_path / 'ground truth0'\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.mkdir(train_path)\n",
    "if not os.path.exists(image_patch_path):\n",
    "    os.mkdir(image_patch_path)\n",
    "if not os.path.exists(label_patch_path):\n",
    "    os.mkdir(label_patch_path)\n",
    "\n",
    "patch_base_name = name\n",
    "axes = 'YXC'\n",
    "sub_sample = 1\n",
    "\n",
    "make_patch_directory(1, 1, train_path)\n",
    "\n",
    "# Load the existing JSON data which is created when making the patch directory and append addition information to it\n",
    "json_file = train_path / \"info.json\"\n",
    "\n",
    "with open(json_file, 'r') as infile:\n",
    "    data = json.load(infile)\n",
    "\n",
    "# add the sub_sample information to the JSON file\n",
    "data['sub_sample'] = sub_sample \n",
    "data['axes'] = axes\n",
    "\n",
    "# Write the modified data back to the JSON file\n",
    "with open(json_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a utility to calculate the number of patches and step size \n",
    "\n",
    "If the image size is a multiple of the patch size (ie image size = 1024, patch size = 256) things work out nice, if not we need some overlap between patches (it we want to cover the entire image).  Below utility calculate the number of division and step size that will be used to create patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_num_divisions(shape, patch_size):\n",
    "    num_divisions = []\n",
    "    step = []\n",
    "\n",
    "    for d in shape:\n",
    "        num_divisions_=math.ceil(d/patch_size)\n",
    "\n",
    "        if num_divisions_ > 1:\n",
    "            remainder = num_divisions_*patch_size-d\n",
    "            overlap = remainder/(num_divisions_-1)\n",
    "            step_ = math.floor(patch_size-overlap)\n",
    "            num_divisions.append(num_divisions_)\n",
    "            step.append(step_)\n",
    "        else:\n",
    "            num_divisions.append(1)\n",
    "            step.append(0)\n",
    "    return num_divisions, step\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop patches and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0 256 256\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_0_0.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_0.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "0 1\n",
      "0 254 256 510\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_0_1.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_1.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "0 2\n",
      "0 508 256 764\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_0_2.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_2.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "0 3\n",
      "0 762 256 1018\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_0_3.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_3.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "1 0\n",
      "179 0 435 256\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_1_0.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_0.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "1 1\n",
      "179 254 435 510\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_1_1.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_1.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "1 2\n",
      "179 508 435 764\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_1_2.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_2.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "1 3\n",
      "179 762 435 1018\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_1_3.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_3.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "2 0\n",
      "358 0 614 256\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_2_0.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_0.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "2 1\n",
      "358 254 614 510\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_2_1.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_1.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "2 2\n",
      "358 508 614 764\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_2_2.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_2.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n",
      "2 3\n",
      "358 762 614 1018\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\input0\\21_force_filtered_2_3.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_3.tif\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_0.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_1.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_2.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_0_3.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_0.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_1.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_2.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_1_3.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_0.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_1.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_2.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n",
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_37308\\2875118385.py:25: UserWarning: D:\\images\\tnia-python-images\\imagesc\\2024_01_12_plant_roots\\labels\\ground truth0\\21_force_filtered_2_3.tif is a low contrast image\n",
      "  imsave(label_patch_name, label_patch)\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imsave\n",
    "\n",
    "patch_size = (256, 256)\n",
    "\n",
    "num_divisions, step = get_num_divisions(im.shape, 256)\n",
    "\n",
    "for i in range(num_divisions[0]):\n",
    "    for j in range (num_divisions[1]):\n",
    "        print(i, j)\n",
    "        sx = i*step[0]\n",
    "        sy = j*step[1]\n",
    "        ex = sx+256\n",
    "        ey = sy+256\n",
    "        print(sx, sy, ex, ey)\n",
    "\n",
    "        im_patch = im[sx:ex, sy:ey]\n",
    "        label_patch = labels[sx:ex, sy:ey]\n",
    "        im_patch_name = os.path.join(image_patch_path, patch_base_name+f\"_{i}_{j}.tif\")\n",
    "        label_patch_name = os.path.join(label_patch_path, patch_base_name+f\"_{i}_{j}.tif\")\n",
    "        \n",
    "        print(im_patch_name)\n",
    "        print(label_patch_name)\n",
    "        print(im_patch.shape)\n",
    "        print(label_patch.shape)\n",
    "        print('-----------------')\n",
    "        imsave(im_patch_name, im_patch)\n",
    "        imsave(label_patch_name, label_patch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dresden-decon-test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
