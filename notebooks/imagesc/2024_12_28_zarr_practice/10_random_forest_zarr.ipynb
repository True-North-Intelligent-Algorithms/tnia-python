{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest machine learning on a sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up a parent path that contains the images and folders for labels, features and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from tnia.io.io_helper import collect_all_images \n",
    "from tnia.nd.ndutil import pad_to_largest\n",
    "import napari\n",
    "\n",
    "parent_path = r'/home/bnorthan/'\n",
    "parent_path = r'/home/bnorthan/besttestset/images/Semantic/'\n",
    "\n",
    "ml_path = os.path.join(parent_path, 'ml2_')\n",
    "ml_labels_path = os.path.join(ml_path, 'ml_labels')\n",
    "ml_features_path = os.path.join(ml_path, 'ml_features')\n",
    "ml_predictions_path = os.path.join(ml_path, 'ml_predictions')\n",
    "\n",
    "if not os.path.exists(ml_labels_path):\n",
    "    os.makedirs(ml_labels_path)\n",
    "if not os.path.exists(ml_features_path):\n",
    "    os.makedirs(ml_features_path)\n",
    "if not os.path.exists(ml_predictions_path):\n",
    "    os.makedirs(ml_predictions_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect images\n",
    "\n",
    "Collect the images and put the 2D image sequence into a padded ND array.  This makes it easy to display in Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = collect_all_images(str(parent_path))\n",
    "padded_images = pad_to_largest(images)\n",
    "\n",
    "padded_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out the number of channels (this logic won't work for a grayscale image) and then calculate the label and features shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = padded_images.shape[-1]\n",
    "label_shape = padded_images.shape[:-1]\n",
    "features_shape = padded_images.shape[:-1] + (num_channels*12,)\n",
    "\n",
    "num_channels, label_shape, features_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the labels, features and predictions (especially the features) could use a lot of memory for a large sequence use Zarr arrays for labels, features and predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ml_labels_path)\n",
    "print(ml_features_path)\n",
    "print(ml_predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_labels = zarr.open(\n",
    "    ml_labels_path,\n",
    "    mode='a',\n",
    "    shape=label_shape,\n",
    "    dtype='i4',\n",
    "    dimension_separator=\"/\",\n",
    ")\n",
    "\n",
    "ml_features = zarr.open(\n",
    "    ml_features_path,\n",
    "    mode='a',\n",
    "    shape=features_shape,\n",
    "    dtype='f4',\n",
    "    dimension_separator=\"/\",\n",
    ")\n",
    "\n",
    "ml_predictions = zarr.open(\n",
    "    ml_predictions_path,\n",
    "    mode='a',\n",
    "    shape=label_shape,\n",
    "    dtype='i4',\n",
    "    dimension_separator=\"/\",\n",
    ")\n",
    "\n",
    "ml_labels.shape, ml_labels.dtype, ml_features.shape, ml_features.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View images, labels and predictions\n",
    "\n",
    "View images, labels and predictions.  We can draw labels in Napari and these labels will be recognized by the subsequent cells. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(padded_images, name='padded_images')\n",
    "viewer.add_labels(ml_labels, name='ml_labels')\n",
    "viewer.add_labels(ml_predictions.astype('uint32'), name='ml_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tnia.machinelearning.random_forest_helper import extract_features_sequence, extract_features\n",
    "padded_images.shape, padded_images.dtype, ml_labels.shape, ml_labels.dtype, ml_features.shape, ml_features.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract features for the entire sequence.  The ```extract_features_sequence``` only computes features for images that have labels.  It returns a label vector and feature vector that can be used for pixel based machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vector, features_vector = extract_features_sequence(padded_images, ml_labels, ml_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a Random Forest Classifier to predict foreground and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "            n_estimators=50, n_jobs=-1, max_depth=10, max_samples=0.05\n",
    "        )\n",
    "\n",
    "clf.fit(features_vector, label_vector-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now predict the entire sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import future\n",
    "\n",
    "for n in range(padded_images.shape[0]):\n",
    "    print('predicting image', n)\n",
    "    image = padded_images[n,:,:,:]\n",
    "    if ml_features[n,:,:,:].sum() == 0:\n",
    "        ml_features[n,:,:,:] = extract_features(image)\n",
    "    features = ml_features[n,:,:,:]\n",
    "\n",
    "    prediction = future.predict_segmenter(features.reshape(-1, features.shape[-1]), clf).reshape(features.shape[:-1]) + 1\n",
    "    prediction = np.squeeze(prediction).astype(np.uint32)\n",
    "    ml_predictions[n,:,:] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_predictions = ml_predictions.astype(np.uint32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_predictions2 = (ml_predictions[:]-1)*5\n",
    "viewer.add_labels(ml_predictions2, name='ml_predictions2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(ml_predictions, name='ml_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vector.min(), features_vector.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easy_augment_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
