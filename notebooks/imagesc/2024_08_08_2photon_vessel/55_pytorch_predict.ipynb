{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Prediction\n",
    "\n",
    "This notebook uses the trained semantic segmentation network for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread as skimread\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from tnia.deeplearning.dl_helper import quantile_normalization\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(764, 762, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#tnia_images_path = Path(\"D:/images/tnia-python-images\")\n",
    "tnia_images_path = Path(r'/home/bnorthan/images/tnia-python-images')\n",
    "parent_path=Path(tnia_images_path / r'imagesc/2024_08_08_2photon_vessel')\n",
    "\n",
    "images_path = parent_path \n",
    "patch_path = parent_path / 'patches'\n",
    "labels_path = parent_path / 'labels'\n",
    "\n",
    "test_name = r'image1.jpg'\n",
    "\n",
    "testim = skimread(images_path  / test_name) \n",
    "\n",
    "print(testim.shape)\n",
    "axes = 'YX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicUNet(\n",
       "  (conv_0): TwoConv(\n",
       "    (conv_0): Convolution(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (D): Dropout(p=0.25, inplace=False)\n",
       "        (A): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv_1): Convolution(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (D): Dropout(p=0.25, inplace=False)\n",
       "        (A): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_1): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_2): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_3): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_4): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_4): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_3): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_2): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_1): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (D): Dropout(p=0.25, inplace=False)\n",
       "          (A): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(patch_path / 'model1')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image to tensor...\n",
    "\n",
    "and predict output segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 764, 762])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bnorthan/mambaforge/envs/segment_everything_fresh/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "testim_ = testim.copy().astype(np.float32)\n",
    "\n",
    "if axes == 'YXC':\n",
    "    for i in range(1):\n",
    "        testim_[:,:,i] = quantile_normalization(\n",
    "            testim[:,:,i],\n",
    "            quantile_low=0.01,\n",
    "            quantile_high=0.998,\n",
    "            clip=True).astype(np.float32)\n",
    "else:\n",
    "    testim_ = quantile_normalization(\n",
    "        testim_,\n",
    "        quantile_low=0.01,\n",
    "        quantile_high=0.998,\n",
    "        clip=True).astype(np.float32)\n",
    "\n",
    "tensor_transform = transforms.Compose([\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "x = tensor_transform(testim_)\n",
    "x = x.unsqueeze(0).to(device)\n",
    "#x = torch.from_numpy(testim_).to(device)\n",
    "\n",
    "print(x.shape)\n",
    "y = model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find bounding boxes of labels\n",
    "\n",
    "Load the bounding boxes for any labels drawn on this image.  This is useful to see self-prediction (prediction on areas that were labeld) vs validation prediction (prediction on areas of image that were not labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_name': 'image1_0', 'bbox': [192, 487, 738, 748]}\n"
     ]
    }
   ],
   "source": [
    "# search for ROI\n",
    "import json\n",
    "\n",
    "labels_image_path = labels_path / 'input0'\n",
    "\n",
    "json_names = list(Path(labels_image_path).glob('*.json'))\n",
    "base_name = test_name.split('.')[0]\n",
    "json_names_ = [x for x in json_names if base_name in x.name]\n",
    "\n",
    "test_ = test_name.split('.')[0]\n",
    "\n",
    "rois=[]\n",
    "\n",
    "for json_name in json_names_:\n",
    "    # open json\n",
    "    with open(json_name, 'r') as f:\n",
    "        json_ = json.load(f)\n",
    "        print(json_)\n",
    "        \n",
    "        y1= json_['bbox'][0]\n",
    "        x1= json_['bbox'][1]\n",
    "        y2= json_['bbox'][2]\n",
    "        x2= json_['bbox'][3]\n",
    "        rois.append([[x1, y1], [x2, y2]])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View in napari\n",
    "\n",
    "View image, prediction and bounding box in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(testim, name='testim')\n",
    "viewer.add_image(y.cpu().detach()[0, 0].numpy(), name='prediction')\n",
    "binary = y.cpu().detach()[0, 0].numpy() > 0.5\n",
    "binary = binary.astype(np.uint8)\n",
    "binary = binary*2\n",
    "viewer.add_labels(binary, name='prediction binary')\n",
    "boxes_layer = viewer.add_shapes(\n",
    "            name=\"Label box\",\n",
    "            face_color=\"transparent\",\n",
    "            edge_color=\"green\",\n",
    "            edge_width=2,\n",
    "        )\n",
    "\n",
    "boxes_layer.add(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
