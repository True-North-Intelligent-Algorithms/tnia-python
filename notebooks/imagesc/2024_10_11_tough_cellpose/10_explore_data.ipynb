{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "\n",
    "This notebook uses the ```napari-easy-augment-batch-dl``` widget to explore and label the data.  If we have a model trained we can also predict using that model. \n",
    "\n",
    "Note:  ```napari-easy-augment-batch-dl``` is a useful tool, especially for labelling, but is currently under construction for other uses.  Right now it **may** be best to use it for labelling and inspecting predictions and do other steps of the deep learning workflow (making patches, training) in notebooks.  (of course you are welcome to try the GUI for other steps and report and hiccups (or disasters) that occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "import os\n",
    "import numpy as np\n",
    "import napari\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT checkpoint loaded successfully\n",
      "found class  PytorchSemanticModel\n",
      "found class  CellPoseInstanceModel\n",
      "creating new log file\n",
      "2024-10-29 08:19:08,165 [INFO] WRITING LOG OUTPUT TO C:\\Users\\bnort\\.cellpose\\run.log\n",
      "2024-10-29 08:19:08,166 [INFO] \n",
      "cellpose version: \t3.0.9 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.14 \n",
      "torch version:  \t2.2.2+cu118\n",
      "found class  MobileSAMModel\n",
      "found class  YoloSAMModel\n",
      "2024-10-29 08:19:13,328 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2024-10-29 08:19:13,330 [INFO] >>>> using GPU\n",
      "2024-10-29 08:19:13,446 [INFO] >>>> loading model D:\\images\\tnia-python-images\\\\imagesc\\\\2024_10_11_tough_cellpose_3\\models\\cellpose_for_protrusions_2\n",
      "2024-10-29 08:19:13,596 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      "2024-10-29 08:19:13,597 [INFO] >>>> model diam_labels =  61.457 (mean diameter of training ROIs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer, label_only = False)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "parent_path =r'D:\\images\\tnia-python-images\\\\imagesc\\\\2024_10_11_tough_cellpose_3'\n",
    "model_path = os.path.join(parent_path, 'models')\n",
    "\n",
    "model_name = 'cellpose_for_protrusions_2'\n",
    "#mod = models.Cellpose(gpu=True, model_type=\"cyto3\")\n",
    "model_type = \"CellPose Instance Model\"\n",
    "batch_dl.load_image_directory(parent_path)\n",
    "\n",
    "# optionally set a pretrained model and settings so we can do prediction\n",
    "if model_name is not None:\n",
    "    batch_dl.network_architecture_drop_down.setCurrentText(model_type)\n",
    "    batch_dl.deep_learning_project.set_pretrained_model(os.path.join(model_path, model_name), model_type)\n",
    "\n",
    "    model = batch_dl.deep_learning_project.models[model_type]\n",
    "    model.prob_thresh = -1\n",
    "    model.flow_thresh = 0.4\n",
    "    model.chan_segment = 2\n",
    "    model.chan2 = 3\n",
    "\n",
    "    widget = batch_dl.param_widgets[model_type]\n",
    "    widget.sync_with_model()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 65535)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_path =r'D:\\images\\tnia-python-images\\\\imagesc\\\\2024_10_07_cellpose_multi_nuclear'\n",
    "\n",
    "test = io.imread(os.path.join(parent_path, 'Empty_02 - Copy.tif')).astype('uint16')\n",
    "\n",
    "test.min(), test.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
