{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform comparison between various results\n",
    "\n",
    "Renders some comparisons between results.  One trick we do in this notebook is to look at only the small objects.  This is a useful test because some deep learning approaches have trouble detecting objects at different scales so can miss small objects if optimized to detect larger objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path =r'D:\\images\\tnia-python-images\\\\imagesc\\\\2024_12_19_sem_grain_size_revisit'\n",
    "image_name = '211122_AM_Al2O3_SE_021.ome.tiff'\n",
    "\n",
    "cyto3 = imread(os.path.join(parent_path, \"cellpose_cyto3_120_segmented.tif\"))\n",
    "custom = imread(os.path.join(parent_path, \"cellpose_custom_segmented.tif\"))\n",
    "herbie = imread(os.path.join(parent_path, \"Herbie_segmented.tif\"))\n",
    "ml_fillholes = imread(os.path.join(parent_path, \"ml_hole_fill_segmented.png\"))\n",
    "img = imread(os.path.join(parent_path, image_name))\n",
    "\n",
    "segmentations = [cyto3, custom, herbie, ml_fillholes]\n",
    "names = ['cyto3', 'custom', 'herbie', 'ml_fillholes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "import numpy as np\n",
    "\n",
    "filtered_segmentations = []\n",
    "\n",
    "for seg in segmentations:\n",
    "    props = regionprops(seg)\n",
    "    filtered = np.zeros_like(seg)\n",
    "    for prop in props:\n",
    "        if prop.area < 1000:\n",
    "            filtered[prop.coords[:,0], prop.coords[:,1]] = prop.label\n",
    "    \n",
    "    filtered_segmentations.append(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(img, name='original')\n",
    "\n",
    "for i, seg in enumerate(filtered_segmentations):\n",
    "    viewer.add_labels(seg, name=names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seg in enumerate(segmentations):\n",
    "    viewer.add_labels(seg, name=names[i] + \"_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
