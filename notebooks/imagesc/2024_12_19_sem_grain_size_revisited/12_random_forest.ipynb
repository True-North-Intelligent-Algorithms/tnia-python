{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Machine Learning\n",
    "\n",
    "In this notebook we perform Random Forest Machine Learning on the SEM Grain image.  We use pre-existing labels provided by Sreenivas Bhattiprolu to train the random classifier.  We use Napari to visualize the labels and (optionally) add additional labels to improve the result.  We train on one image then apply the model to a second image (that is not used for training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open train and test image and pre-existing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imsave\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tnia.machinelearning.random_forest_helper import extract_features\n",
    "\n",
    "parent_path =r'D:\\images\\tnia-python-images\\\\imagesc\\\\2024_12_19_sem_grain_size_revisit'\n",
    "parent_path = r'/home/bnorthan/images/tnia-python-images/imagesc/2024_12_19_sem_grain_size_revisit'\n",
    "\n",
    "training_data_path = os.path.join(parent_path,r'training_data')\n",
    "\n",
    "im_name = '211122_AM_Al2O3_SE_021.ome.tiff'\n",
    "background_name = '211122_AM_Al2O3_SE_021_sp_background_binary.tif'\n",
    "grains_name = '211122_AM_Al2O3_SE_021_sp_grains_binary.tif'\n",
    "inclusions_name = '211122_AM_Al2O3_SE_021_sp_inclusions_binary.tif'\n",
    "\n",
    "validation_name = r'211122_AM_Al2O3_SE_027_sp.tif'\n",
    "\n",
    "im = imread(os.path.join(training_data_path,im_name))\n",
    "background = (imread(os.path.join(training_data_path,background_name))//255)\n",
    "grains = (imread(os.path.join(training_data_path,grains_name))//255)*2\n",
    "inclusions = (imread(os.path.join(training_data_path,inclusions_name))//255)*3\n",
    "predictions = np.zeros_like(background)\n",
    "labels = np.zeros_like(background)\n",
    "\n",
    "validation_im = imread(os.path.join(training_data_path,validation_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View in Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari \n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(im)\n",
    "viewer.add_labels(background, name='background')\n",
    "viewer.add_labels(grains, name='grains')\n",
    "viewer.add_labels(inclusions, name='inclusions')\n",
    "viewer.add_labels(predictions, name='predictions')\n",
    "#viewer.add_labels(labels, name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = extract_features(im)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label and feature vector\n",
    "\n",
    "In this step we create a label and feature vector using the data at the non-zero labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a copy of the background image\n",
    "labels = background.copy()\n",
    "## now copy the grain labels, but only at non-zero locations (as not to overwrite the background)\n",
    "labels[labels==0] = grains[labels==0]\n",
    "## now copy the inclusion labels, but only at non-zero locations (as not to overwrite the background and grains)\n",
    "labels[labels==0] = inclusions[labels==0]\n",
    "print(labels.min(), labels.max())\n",
    "label_vector = labels[labels>0]\n",
    "features_vector = features[labels>0,:]\n",
    "print(label_vector.shape, features_vector.shape)\n",
    "\n",
    "viewer.add_labels(labels, name='labels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we use a utility to rebalance the data\n",
    "\n",
    "There are many more grain pixels, so we rebalance ```smote.fit_resample``` creates artificial samples by interpolating between real points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(features_vector, label_vector)\n",
    "\n",
    "print(X_resampled.shape, y_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=20)\n",
    "#clf.fit(features_vector, label_vector-1)\n",
    "clf.fit(X_resampled, y_resampled-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import future\n",
    "\n",
    "\n",
    "predictions = future.predict_segmenter(features.reshape(-1, features.shape[-1]), clf).reshape(features.shape[:-1]) + 1\n",
    "predictions = np.squeeze(predictions).astype(np.uint32)\n",
    "print(predictions.min(), predictions.max())\n",
    "viewer.layers['predictions'].data = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_grains = predictions==2\n",
    "from skimage.measure import label\n",
    "\n",
    "instances = label(predicted_grains)\n",
    "\n",
    "viewer.add_labels(instances, name='instances')\n",
    "\n",
    "predicted_background = np.any([predictions==1, predictions==3], axis=0)\n",
    "\n",
    "from skimage.morphology import dilation, closing, disk\n",
    "# utility to close small gaps in boundary\n",
    "def close_small_gaps(image, disk_size):\n",
    "    from skimage.morphology import closing, disk\n",
    "    dilated_image = dilation(image, disk(disk_size))\n",
    "    return closing(dilated_image, disk(disk_size))\n",
    "\n",
    "closed_image = close_small_gaps(predicted_background, 2)\n",
    "\n",
    "inverted_image = ~closed_image\n",
    "instances_after_closing = label(inverted_image)\n",
    "\n",
    "viewer.add_labels(instances_after_closing, name='instances_after_closing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict validation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features = extract_features(validation_im)\n",
    "validation_predictions = future.predict_segmenter(validation_features.reshape(-1, validation_features.shape[-1]), clf).reshape(validation_features.shape[:-1]) + 1\n",
    "\n",
    "validation_instances = label(validation_predictions==2)\n",
    "viewer.add_labels(validation_predictions, name='validation predictions')\n",
    "viewer.add_labels(validation_instances, name='validation labeled grains')\n",
    "\n",
    "validation_background = np.any([validation_predictions==1, validation_predictions==3], axis=0)\n",
    "validation_closed_image = close_small_gaps(validation_background, 2)\n",
    "validation_inverted_image = ~validation_closed_image\n",
    "validation_instances_closed = label(validation_inverted_image)\n",
    "viewer.add_labels(validation_instances_closed, name='validation instances after closing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
