{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import os\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl\n",
    "from napari_easy_augment_batch_dl.deep_learning_project import DLModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image file is  D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\IMG_6554_roi.tif\n",
      "labelsum is  372330\n",
      "(630, 810) (630, 810)\n",
      "IMG_6554_roi_0\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\labels\\input0/IMG_6554_roi_0.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\labels\\ground truth0/IMG_6554_roi_0.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\labels\\input0/IMG_6554_roi_0.tif\n",
      "D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\labels\\ground truth0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deep_learning_project.py (354): D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\labels\\ground truth0\\IMG_6554_roi_0.tif is a low contrast image\n",
      "deep_learning_project.py (373): D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\annotations\\class_0\\IMG_6554_roi.tif is a low contrast image\n",
      "deep_learning_project.py (378): D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores\\predictions\\class_0\\IMG_6554_roi.tif is a low contrast image\n"
     ]
    }
   ],
   "source": [
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer, label_only = False)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "parent_path =r'D:\\images\\tnia-python-images\\imagesc\\2024_09_18_spores' \n",
    "model_path = os.path.join(parent_path, 'models')\n",
    "\n",
    "batch_dl.load_image_directory(parent_path)\n",
    "\n",
    "# try loading the model (at the beginning it may not exist yet, so don't worry if it fails)\n",
    "try:\n",
    "    batch_dl.deep_learning_project.set_pretrained_model(os.path.join(model_path, 'model1'), DLModel.STARDIST)\n",
    "    batch_dl.network_architecture_drop_down.setCurrentText(DLModel.STARDIST)\n",
    "except:\n",
    "    print('No model found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting bounding boxes for image data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 704x1024 283 objects, 1375.5ms\n",
      "Speed: 10.6ms preprocess, 1375.5ms inference, 7.8ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT checkpoint loaded successfully\n",
      "area 320.0 4865480.0\n",
      "label_num 1 283\n",
      "solidity 0.29025026771903384 0.9905350204244296\n",
      "circularity 0.04106902952497253 0.963530105262448\n",
      "mean_intensity 12.302475323616486 208.10117056856188\n",
      "10th_percentile_intensity 9.0 199.0\n",
      "mean_hue 0.0 0.0\n",
      "mean_saturation 0.0 0.0\n",
      "predicted_iou 0.6057274341583252 0.9763306975364685\n",
      "stability_score 0.3064901530742645 0.9942810535430908\n",
      "Predicting bounding boxes for image data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 2752x4096 790 objects, 1494.2ms\n",
      "Speed: 108.3ms preprocess, 1494.2ms inference, 29.0ms postprocess per image at shape (1, 3, 4096, 4096)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT checkpoint loaded successfully\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment_bees_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
