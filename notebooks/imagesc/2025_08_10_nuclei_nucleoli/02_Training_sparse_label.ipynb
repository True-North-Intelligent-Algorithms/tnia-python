{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Napari-Easy-Augment-Batch-DL to load and label images\n",
    "\n",
    "This notebook starts up Napari-Easy-Augment-Batch-DL and points it to our project directories (we are training 2 models).  At the beginning of a project this directory is simply the location of our collection of images.  For the nuclei/nucleoli example it will be the 2D slices we extracted and saved in the ```01_extract 2D image.ipynb``` notebook. \n",
    "\n",
    "For an overview of how ```napari-easy-augment-batch-dl``` is used to load and label images, and how data should be organized see [here](https://true-north-intelligent-algorithms.github.io/napari-easy-augment-batch-dl/load_and_label/).\n",
    "\n",
    "## Semantic Labeling vs Instance Labeling\n",
    "\n",
    "In this example we will use instance labeling\n",
    "\n",
    "**Semantic Labeling** Each pixel is assigned a class (background, vessel, cell, brain barrier) but do not distinquish individual objects (instances).  In this example there will be four classes, so the maximum index used is 4. \n",
    "\n",
    "**Instance Labeling** In instance labeling each pixel belonging to an object is given a unique ID.  Thus the maximum index will correspond to the number of objects.  For example if there are 40 objects the max index will be 40, if there are 10000 objects the max index will be 10000.\n",
    "\n",
    "## Sparse Labeling vs Dense Labeling\n",
    "\n",
    "In this example we will use dense labeling.  \n",
    "\n",
    "**Sparse Labeling**:  Not every pixel has to be labeled.  However some background needs to be labeled to differentiate between background pixels and unlabeled pixels.  For example if there were 2 foreground classes use label 1 for background, 2 for \"class 1\", and 3 for \"class 2\".  Unlabeled pixels (0) will be ignored. \n",
    "\n",
    "**Dense Labeling**:  Every foreground pixel needs to be labeled however background does not need to be labeled.  If there were 2 foreground classes, use 1 for \"class 1\", 2 for \"class 2\" and then the remaining pixels (0) will be treated as background. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and check versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bnort\\miniconda3\\envs\\microsam_cellpose\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\bnort\\miniconda3\\envs\\microsam_cellpose\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\bnort\\miniconda3\\envs\\microsam_cellpose\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\bnort\\miniconda3\\envs\\microsam_cellpose\\Lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\segment-everything\\src\\segment_everything\\vendored\\efficientvit\\models\\nn\\ops.py:407: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "napari version 0.5.6\n",
      "numpy version 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl\n",
    "\n",
    "# for trouble shooting print the napari and numpy version. This can give us clues if there are dependency issues\n",
    "print('napari version', napari.__version__)\n",
    "print('numpy version', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Start Napari and Easy Augment Batch DL and open images\n",
    "\n",
    "Start Napari, show Easy-Augment-Batch-DL and show the parent directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_32392\\697197989.py:3: DeprecationWarning: The 'label_only' parameter is deprecated. Please use the 'mode' parameter instead.\n",
      "  batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT checkpoint loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.io:WRITING LOG OUTPUT TO C:\\Users\\bnort\\.cellpose\\run.log\n",
      "INFO:cellpose.io:\n",
      "cellpose version: \t3.1.0 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.11 \n",
      "torch version:  \t2.6.0\n",
      "INFO:cellpose.models:>> cyto3 << model set to be used\n",
      "INFO:cellpose.core:** TORCH CUDA version installed and working. **\n",
      "INFO:cellpose.core:>>>> using GPU (CUDA)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found framework CellPoseInstanceFramework\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.models:>>>> loading model C:\\Users\\bnort\\.cellpose\\models\\cyto3\n",
      "INFO:cellpose.models:>>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found framework MobileSAMFramework\n",
      "Found framework YoloSAMFramework\n",
      "Found framework RandomForestFramework\n",
      "Found framework VesselsSemanticFramework\n",
      "Found framework MicroSamInstanceFramework\n",
      "Zarr store already up-to-date.\n",
      "Zarr store already up-to-date.\n",
      "Adding widget for CellPose Instance Framework\n",
      "Adding widget for MobileSAM Model\n",
      "Adding widget for Yolo SAM Model\n",
      "Adding widget for Random Forest Model\n",
      "Adding widget for Monai UNET Model\n",
      "Adding widget for Micro-sam Instance Framework\n",
      "Adding object boxes layer\n",
      "Adding predicted object boxes layer\n",
      "Adding label boxes\n",
      "Data changed\n",
      "Data changed\n",
      "Adding object boxes\n",
      "Adding predicted object boxes\n",
      "Setting object box classes\n",
      "Setting predicted object box classes\n",
      "binding key events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bnort\\miniconda3\\envs\\microsam_cellpose\\Lib\\site-packages\\napari\\layers\\utils\\style_encoding.py:257: RuntimeWarning: Applying the encoding failed. Using the safe fallback value instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "parent_path = r'D:\\images\\tnia-python-images\\imagesc\\2025_08_10_nuclei_nuceoli\\nucleoli_project'\n",
    "batch_dl.load_image_directory(parent_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsam_cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
