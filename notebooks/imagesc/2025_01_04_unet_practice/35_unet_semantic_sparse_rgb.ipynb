{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a sparse semantic unet on RGB image\n",
    "\n",
    "In this notebook we work out the details for training a sparse semeantic unet to predict pixel classes for RGB images. \n",
    "\n",
    "Sparse means we don't have to label every pixel in an ROI.  We label each class (including a background class labeled with 1).  We then ignore the unlabeled pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:  Note on Linux for some reason we have to import and show Napari before importing PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "\n",
    "from tnia.deeplearning.dl_helper import quantile_normalization\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tnia.deeplearning.dl_helper import collect_training_data, divide_training_data\n",
    "from tnia.plotting.plt_helper import imshow_multi2d, random_label_cmap\n",
    "from semantic_dataset import SemanticDataset\n",
    "import random\n",
    "from unet import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from semantic_helper import train3\n",
    "from monai.networks.nets import BasicUNet\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Cuda is present\n",
    "\n",
    "If cuda is not present training will be slow... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_present = torch.cuda.is_available()\n",
    "ndevices = torch.cuda.device_count()\n",
    "use_cuda = cuda_present and ndevices > 0\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # \"cuda:0\" ... default device, \"cuda:1\" would be GPU index 1, \"cuda:2\" etc\n",
    "print(\"number of devices:\", ndevices, \"\\tchosen device:\", device, \"\\tuse_cuda=\", use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parent Path\n",
    "\n",
    "This is the path that contains the images we will work with and pre-existing patches that would have been created in notebook ```33_label_semantic_sparse_rgb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tnia_images_path = Path(r\"D:\\images\")\n",
    "parent_path = r'C:\\Users\\bnort\\Documents\\...'\n",
    "parent_path = r'/home/bnorthan/bekonbits/images/Columbia_Semantic_Sparse/'\n",
    "\n",
    "train_path = os.path.join(parent_path, 'patches')\n",
    "\n",
    "image_patch_path = train_path + '/ground truth0'\n",
    "label_patch_path = train_path + '/input0'\n",
    "\n",
    "model_path = os.path.join(parent_path,'models')\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(image_patch_path):\n",
    "    print('image_patch_path does not exist')\n",
    "\n",
    "if not os.path.exists(label_patch_path):\n",
    "    print('label_patch_path does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect training data\n",
    "\n",
    "Collect the training data that would have been created in ```33_label_semantic_sparse_rgb.ipynb```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = collect_training_data(train_path, sub_sample=1, downsample=False, normalize_input=False, add_trivial_channel=False, relabel=False)\n",
    "\n",
    "print('Number of input images', len(X))\n",
    "print('Number of ground truth images ', len(Y))\n",
    "\n",
    "print('Size of first input image', X[0].shape)\n",
    "print('Size of first ground truth image ', Y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val = divide_training_data(X, Y, 2, to_numpy=False)\n",
    "\n",
    "print('Number of training images', len(X_train))\n",
    "print('Number of validaiton images ', len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "X_test = X_val\n",
    "Y_test = Y_val\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.astype(np.int16)-1\n",
    "Y_val = Y_val.astype(np.int16)-1\n",
    "Y_test = Y_test.astype(np.int16)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.min(), Y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Training Data\n",
    "\n",
    "Just make sure it looks right and labels correspond to objects properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "X_ = X_train[n]\n",
    "Y_ = Y_train[n]\n",
    "print(Y_.dtype)\n",
    "\n",
    "print(X_.shape, Y_.shape)\n",
    "print(X_.min(), X_.max())\n",
    "print(X_.dtype, X_.shape, X_.min(), X_.max())\n",
    "fig=imshow_multi2d([X_, Y_], ['input', 'label'], 1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SemanticDataset(X_train, Y_train, crop_size=256)\n",
    "test_dataset = SemanticDataset(X_val, Y_val, crop_size=256)\n",
    "val_dataset = SemanticDataset(X_val, Y_val, crop_size=256)\n",
    "\n",
    "# verify that the dataset is working\n",
    "raw, mask = train_dataset[random.randrange(len(train_dataset))]\n",
    "raw = np.transpose(raw, (1,2,0))\n",
    "raw.shape,mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a few datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, mask = train_dataset[random.randrange(len(train_dataset))]\n",
    "fig = imshow_multi2d([np.transpose(raw, (1,2,0)), mask[0]], ['Image', 'Labels'], 1, 2, 10, 10,colormaps=['gray', random_label_cmap()])\n",
    "print(mask.min(), mask.max())\n",
    "\n",
    "raw, mask = train_dataset[random.randrange(len(train_dataset))]\n",
    "fig = imshow_multi2d([np.transpose(raw, (1,2,0)), mask[0]], ['Image', 'Labels'], 1, 2, 10, 10,colormaps=['gray', random_label_cmap()])\n",
    "print(mask.min(), mask.max())\n",
    "\n",
    "raw, mask = train_dataset[1500]\n",
    "fig = imshow_multi2d([np.transpose(raw, (1,2,0)), mask[0]], ['Image', 'Labels'], 1, 2, 10, 10,colormaps=['gray', random_label_cmap()])\n",
    "print(mask.min(), mask.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up unet\n",
    "\n",
    "We use monai BasicUnet.\n",
    "\n",
    "Since image is RGB in_channels are 3\n",
    "\n",
    "Since the dataset we are working with has 3 classes, out_channels are 3\n",
    "\n",
    "No activation function since we are using CrossEntropyLoss which applies softmax\n",
    "Note: predictor will need to use a softmax activation function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "dtype = torch.LongTensor\n",
    "\n",
    "net = BasicUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    #features=[16, 16, 32, 64, 128, 16],\n",
    "    act=None,\n",
    "    #norm=\"batch\",\n",
    "    #norm=None,\n",
    "    #dropout=0.25,\n",
    ")\n",
    "\n",
    "net = torch.load( Path(model_path) / 'model_Jan27_batchfix3.pth')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "writer = SummaryWriter(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size =32 \n",
    "test_batch_size = 1\n",
    "\n",
    "learning_rate = 5e-5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# make dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=test_batch_size)\n",
    "\n",
    "training_steps = 5000\n",
    "\n",
    "train3(train_loader, val_loader, net, loss_fn, optimizer, dtype, 150, device)\n",
    "#test_data_loader(train_loader, val_loader, net2, loss_fn, optimizer, dtype, 1, 100, device, writer)\n",
    "#train(train_loader, val_loader, net2, loss_fn, None, optimizer, dtype, 10, device, writer)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(net, Path(model_path) / 'model_Jan27_batchfix4.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    #features, label = train_loader.dataset[random.randrange(len(train_loader.dataset))]\n",
    "    features, label = train_loader.dataset[i]\n",
    "    \n",
    "    net.eval()\n",
    "    features_tensor = torch.from_numpy(features).unsqueeze(0).to(device)       \n",
    "    #features = features.todevice()\n",
    "    predicted = net(features_tensor)\n",
    "\n",
    "    print(predicted.shape, features.shape)\n",
    "\n",
    "    features = np.transpose(features, (1,2,0))\n",
    "\n",
    "    predicted.shape\n",
    "    c1 = predicted[0,0,:,:].cpu().detach().numpy()\n",
    "    c2 = predicted[0,1,:,:].cpu().detach().numpy()\n",
    "    c3 = predicted[0,2,:,:].cpu().detach().numpy()\n",
    "    fig = imshow_multi2d([features, c1, c2, c3], ['Image', 'Class 1', 'Class 2', 'Class 3'], 1, 4, 10, 10,colormaps=['gray', 'viridis', 'viridis', 'viridis'])\n",
    "\n",
    "    features, label = train_loader.dataset[i]\n",
    "    net.train()\n",
    "    features_tensor = torch.from_numpy(features).unsqueeze(0).to(device)       \n",
    "    #features = features.todevice()\n",
    "    predicted = net(features_tensor)\n",
    "\n",
    "    print(predicted.shape, features.shape)\n",
    "\n",
    "    features = np.transpose(features, (1,2,0))\n",
    "\n",
    "    predicted.shape\n",
    "    c1 = predicted[0,0,:,:].cpu().detach().numpy()\n",
    "    c2 = predicted[0,1,:,:].cpu().detach().numpy()\n",
    "    c3 = predicted[0,2,:,:].cpu().detach().numpy()\n",
    "    fig = imshow_multi2d([features, c1, c2, c3], ['Image', 'Class 1', 'Class 2', 'Class 3'], 1, 4, 10, 10,colormaps=['gray', 'viridis', 'viridis', 'viridis'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
