{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tnia.deeplearning.dl_helper import quantile_normalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tnia.deeplearning.dl_helper import collect_training_data, divide_training_data\n",
    "from tnia.plotting.plt_helper import imshow_multi2d\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_present = torch.cuda.is_available()\n",
    "ndevices = torch.cuda.device_count()\n",
    "use_cuda = cuda_present and ndevices > 0\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # \"cuda:0\" ... default device, \"cuda:1\" would be GPU index 1, \"cuda:2\" etc\n",
    "print(\"number of devices:\", ndevices, \"\\tchosen device:\", device, \"\\tuse_cuda=\", use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "tnia_images_path = Path(r\"D:\\images\")\n",
    "parent_path = r'C:\\Users\\bnort\\Documents\\...'\n",
    "parent_path = r'/home/bnorthan/besttestset/images/Semantic_Sparse/'\n",
    "\n",
    "train_path = os.path.join(parent_path, 'patches')\n",
    "\n",
    "image_patch_path = train_path + '/ground truth0'\n",
    "label_patch_path = train_path + '/input0'\n",
    "\n",
    "model_path = os.path.join(parent_path,'models')\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(image_patch_path):\n",
    "    print('image_patch_path does not exist')\n",
    "\n",
    "if not os.path.exists(label_patch_path):\n",
    "    print('label_patch_path does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.LongTensor\n",
    "\n",
    "net = torch.load( Path(model_path) / 'model_Jan27_batchfix4.pth')\n",
    "net = torch.load( Path(model_path) / 'ok.pth')\n",
    "device = torch.device(\"cuda\")\n",
    "net=net.to(device)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = net.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = Path(parent_path)\n",
    "models_path = Path(parent_path) / 'models'\n",
    "\n",
    "im_name = '20240905200636_SEP05ERLHS247450b.jpg'\n",
    "im_name = '20240910210212_SEP10PRSP2424346.jpg'\n",
    "#im_name = '20240911211757_SEP11EROSP245615.jpg'\n",
    "#labels_name = '211122_AM_Al2O3_SE_021_sp_labels.tif'\n",
    "im = imread(str(parent_path / (im_name)))\n",
    "\n",
    "print(im.min(), im.max(), im.mean(), im.shape)\n",
    "im = quantile_normalization(im)\n",
    "print(im.min(), im.max(), im.mean(), im.shape)\n",
    "\n",
    "im_to_test = im#[0:1024, 0:1024, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_to_test.dtype\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = im_to_test.transpose(2,0,1).astype(np.float32)\n",
    "\n",
    "features_tensor = torch.from_numpy(features).unsqueeze(0).to(device)       \n",
    "#features = features.todevice()\n",
    "with torch.no_grad():\n",
    "    #predicted = net(features_tensor)\n",
    "    outputs = []\n",
    "    for chunk in torch.chunk(features_tensor, chunks=4, dim=3):  # Divide input into smaller parts\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs.append(net(chunk))\n",
    "        del chunk\n",
    "        torch.cuda.empty_cache()\n",
    "    predicted = torch.cat(outputs, dim=3)\n",
    "\n",
    "\n",
    "print(predicted.shape, features.shape)\n",
    "\n",
    "features = np.transpose(features, (1,2,0))\n",
    "\n",
    "predicted.shape\n",
    "c1 = predicted[0,0,:,:].cpu().detach().numpy()\n",
    "c2 = predicted[0,1,:,:].cpu().detach().numpy()\n",
    "c3 = predicted[0,2,:,:].cpu().detach().numpy()\n",
    "fig = imshow_multi2d([features, c1, c2, c3], ['Image', 'Class 1', 'Class 2', 'Class 3'], 1, 4, 10, 10,colormaps=['gray', 'viridis', 'viridis', 'viridis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply softmax along the class dimension (dim=1)\n",
    "probabilities = F.softmax(predicted, dim=1)\n",
    "predicted_classes = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "p1 = probabilities[0,0,:,:].cpu().detach().numpy()\n",
    "p2 = probabilities[0,1,:,:].cpu().detach().numpy()\n",
    "p3 = probabilities[0,2,:,:].cpu().detach().numpy()\n",
    "fig = imshow_multi2d([features, p1, p2, p3], ['Image', 'Class 1', 'Class 2', 'Class 3'], 1, 4, 10, 10,colormaps=['gray', 'viridis', 'viridis', 'viridis'])\n",
    "\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edges = predicted_classes.cpu().detach().numpy()\n",
    "\n",
    "edges = edges+1\n",
    "edges[edges!=2] = 0\n",
    "edges.shape\n",
    "viewer.add_labels(edges, name='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(features, contrast_limits=[0,1])\n",
    "viewer.add_image(c1)\n",
    "viewer.add_image(c2)\n",
    "viewer.add_image(c3)\n",
    "viewer.add_labels(predicted_classes[0].cpu().detach().numpy()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
